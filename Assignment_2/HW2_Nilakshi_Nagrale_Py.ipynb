{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install and import necessary libraries"
      ],
      "metadata": {
        "id": "FTB3IBnA1AgB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAJnl5YK08b8",
        "outputId": "b12420e2-3c25-4c92-fa6b-86cdf859bee7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.2\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fastparquet) (1.26.4)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2.9.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from fastparquet) (2024.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->fastparquet) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (4.12.2)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas gensim scikit-learn torch torchvision\n",
        "!pip install contractions\n",
        "!pip install ipython-autotime\n",
        "!pip install fastparquet\n",
        "!pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import urllib.request\n",
        "import unicodedata\n",
        "import multiprocessing\n",
        "import warnings\n",
        "import nltk\n",
        "import contractions\n",
        "import gensim.downloader as api\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from torch.utils.data.sampler import RandomSampler, BatchSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "djbszE5X1kpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aad794f-0a8a-4052-d60e-ad8e2a869f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 278 µs (started: 2025-02-14 00:15:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set config Values\n"
      ],
      "metadata": {
        "id": "Ig2kgTITm1FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CURRENT_DIR = os.getcwd()\n",
        "\n",
        "class ConfigValues:\n",
        "    RANDOM_STATE_VALUE = 42\n",
        "    MAX_TFIDF_FEATURES = 45000\n",
        "    TEST_SPLIT = 0.2\n",
        "    N_SAMPLES_EACH_CLASS = 50000\n",
        "    DATA_PATH = os.path.join(\n",
        "        CURRENT_DIR, \"amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
        "    )\n",
        "    PARQUET_PATH = os.path.join(CURRENT_DIR, \"amazon_reviews_og.parquet\")\n",
        "    URL = \"https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
        "\n",
        "class W2VConfigValues:\n",
        "    GOOGLE_PRETRAINED_MODEL = \"word2vec-google-news-300\"\n",
        "    # TO DO: change variables\n",
        "    PRETRAINED_OG_PATH = os.path.join(\n",
        "        gensim.downloader.BASE_DIR, GOOGLE_PRETRAINED_MODEL, f\"{GOOGLE_PRETRAINED_MODEL}.gz\"\n",
        "    )\n",
        "    PRETRAINED_SAVED_PATH = os.path.join(\n",
        "        CURRENT_DIR, GOOGLE_PRETRAINED_MODEL, f\"{GOOGLE_PRETRAINED_MODEL}.gz\"\n",
        "    )\n",
        "    WINDOW_SIZE = 11\n",
        "    MAX_LENGTH = 300\n",
        "    EMBEDDING_SIZE = 300\n",
        "    MIN_WORD_COUNT = 10\n",
        "    CUSTOM_MODEL_PATH = os.path.join(CURRENT_DIR, \"word2vec-custom.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1YvI4b8zXZS",
        "outputId": "3a0c1998-6ebf-42f8-d5d5-4e93e89d5f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 708 µs (started: 2025-02-14 00:15:17 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Google Pretrained Model for future use"
      ],
      "metadata": {
        "id": "W1BQKShi3Kkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_pretrained():\n",
        "    if not os.path.exists(W2VConfigValues.PRETRAINED_SAVED_PATH):\n",
        "        os.makedirs(W2VConfigValues.GOOGLE_PRETRAINED_MODEL, exist_ok=True)\n",
        "        pretrained_model = api.load(W2VConfigValues.GOOGLE_PRETRAINED_MODEL)\n",
        "        shutil.copyfile(\n",
        "            W2VConfigValues.PRETRAINED_OG_PATH, W2VConfigValues.PRETRAINED_SAVED_PATH\n",
        "        )\n",
        "    else:\n",
        "        pretrained_model = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(\n",
        "            W2VConfigValues.PRETRAINED_SAVED_PATH, binary=True\n",
        "        )\n",
        "    return pretrained_model\n",
        "\n",
        "\n",
        "# Load the pretrained model\n",
        "google_pretrained_model = load_model_pretrained()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbv3sqRK3JOz",
        "outputId": "44799546-a973-4400-cf5d-e38bc661fd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 43.4 s (started: 2025-02-13 23:49:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Preprocess dataset\n",
        "\n",
        "Reference :\n",
        "- https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests\n",
        "\n",
        "- https://inside-machinelearning.com/en/open-parquet-python/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DzlkCEAC10as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# url = \"https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
        "# data = pd.read_csv(url, sep='\\t', compression='gzip', on_bad_lines='skip')\n",
        "\n",
        "os.makedirs(os.path.dirname(ConfigValues.DATA_PATH), exist_ok=True)\n",
        "if not os.path.exists(ConfigValues.DATA_PATH):\n",
        "    url = ConfigValues.URL\n",
        "    file_name = ConfigValues.DATA_PATH\n",
        "\n",
        "    # Stream and download heavy file in chunks\n",
        "    with requests.get(url, stream=True) as response:\n",
        "        if response.status_code == 200:\n",
        "            with open(file_name, \"wb\") as file:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    file.write(chunk)\n",
        "            print(f\"Dataset downloaded successfully.\")\n",
        "        else:\n",
        "            print(f\"Failed to download the file. HTTP Status: {response.status_code}\")\n",
        "\n",
        "else:\n",
        "    print(f\"File '{ConfigValues.DATA_PATH}' already exists.\")\n",
        "\n",
        "# Load dataset\n",
        "if os.path.exists(ConfigValues.PARQUET_PATH):\n",
        "    print(\"Loading dataset from Parquet\")\n",
        "    data = pd.read_parquet(ConfigValues.PARQUET_PATH)\n",
        "else:\n",
        "    print(\"Loading dataset from TSV\")\n",
        "    data = pd.read_csv(ConfigValues.DATA_PATH, sep='\\t', compression='gzip', on_bad_lines='skip')\n",
        "\n",
        "data = data[['review_body', 'star_rating']]\n",
        "data['star_rating'] = pd.to_numeric(data['star_rating'], errors='coerce')\n",
        "data = data.dropna(subset=['star_rating'])\n",
        "data['star_rating'] = data['star_rating'].astype(int)\n",
        "data = data.dropna(subset=['review_body'])\n",
        "\n",
        "# Save to Parquet for faster future loads\n",
        "print(\"Saving dataset to Parquet format for faster access next time\")\n",
        "data.to_parquet(ConfigValues.PARQUET_PATH, engine='fastparquet')\n",
        "# data.head(10)"
      ],
      "metadata": {
        "id": "9DBqe7Uc1zO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aafa23f3-2612-43b2-a669-aeaecad4b276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded successfully.\n",
            "Loading dataset from TSV\n",
            "Saving dataset to Parquet format for faster access next time\n",
            "time: 1min 37s (started: 2025-02-13 22:50:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balance the dataset (50k samples per rating) and Assign Ternary Labels\n",
        "\n"
      ],
      "metadata": {
        "id": "ONN6ueEJ2H6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_data = data.groupby(\"star_rating\").apply(lambda x: x.sample(ConfigValues.N_SAMPLES_EACH_CLASS, replace=True)).reset_index(drop=True)\n",
        "\n",
        "def get_label(rating):\n",
        "       return 1 if rating > 3 else 2 if rating < 3 else 3\n",
        "\n",
        "balanced_data[\"label\"] = balanced_data[\"star_rating\"].apply(get_label)\n",
        "\n",
        "num_rows = balanced_data.shape[0]\n",
        "print(\"Number of rows:\", num_rows)\n",
        "# check if labelled corectly\n",
        "sampled_data = balanced_data.groupby(\"label\").apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
        "print(sampled_data)\n"
      ],
      "metadata": {
        "id": "CNdMzk6V2Mbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a33e6f-83f9-4043-a114-0be9080fb85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 250000\n",
            "                                         review_body  star_rating  label\n",
            "0  I previously thought that vTech was the best p...            5      1\n",
            "1  I am on my second Onetouch 8650.  I had to shi...            1      2\n",
            "2  Very good quality case, horrible keyboard. It'...            3      3\n",
            "time: 494 ms (started: 2025-02-13 22:52:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean & Process Data\n",
        "\n",
        "From Assigment 1:\n",
        "\n",
        "Using regex expressions to match and replace the below items with empty strings:\n",
        "\n",
        "- change all to lower case\n",
        "\n",
        "- URLs\n",
        "\n",
        "- emails\n",
        "\n",
        "- HTML tags\n",
        "\n",
        "- punctuations\n",
        "\n",
        "- extra spaces\n",
        "\n",
        "- special / non-alphabetical characters\n"
      ],
      "metadata": {
        "id": "Bkt6FpqzBIWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clean & preprocess balanced_data\n",
        "balanced_data.dropna(inplace=True)\n",
        "balanced_data[\"review_body\"] = balanced_data[\"review_body\"].astype(str)\n",
        "\n",
        "# Remove URLs first\n",
        "def remove_html_urls(text):\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "    return text\n",
        "\n",
        "# REmove spaces & spl chars\n",
        "def remove_space_characters(text):\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "  text = re.sub(r'[a-zA-Z0-9_\\-\\.]+@[a-zA-Z0-9_\\-\\.]+\\.[a-zA-Z]{2,5}', ' ', text)\n",
        "  return text\n",
        "\n",
        "# Stop Words\n",
        "stop_owrds = set(stopwords.words('english'))\n",
        "negitive_words = ['nor', 'no', 'not', 'none', 'nowhere' 'never', 'neither', 'nobody']\n",
        "refined_stopwords = [word for word in stop_owrds if word not in negitive_words]\n",
        "def remove_stop_words(text):\n",
        "  words = word_tokenize(text)\n",
        "  filtered_words = [word for word in words if word.lower() not in refined_stopwords]\n",
        "  return ' '.join(filtered_words)\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "  words = word_tokenize(text)\n",
        "  lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "  return ' '.join(lemmatized_words)\n",
        "\n",
        "balanced_data[\"review_body\"] = balanced_data[\"review_body\"].apply(remove_html_urls)\n",
        "balanced_data[\"review_body\"] = balanced_data[\"review_body\"].apply(remove_space_characters)\n",
        "balanced_data[\"review_body\"] = balanced_data[\"review_body\"].apply(remove_stop_words)\n",
        "balanced_data[\"review_body\"] = balanced_data[\"review_body\"].apply(lemmatize_text)\n",
        "balanced_data['review_body'] = balanced_data['review_body'].apply(lambda x: contractions.fix(x))\n",
        "\n",
        "# Drop reviews that are empty\n",
        "balanced_data = balanced_data.loc[balanced_data[\"review_body\"].str.strip() != \"\"]\n",
        "\n",
        "# Tokenize Reviews\n",
        "balanced_data[\"review_body\"] = balanced_data[\"review_body\"].apply(word_tokenize)\n",
        "balanced_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "fH8eS8gMBLjO",
        "outputId": "b7874210-ae39-449c-bfba-ff21a07e3a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_body  star_rating  label  \\\n",
              "0  [GOT, BURNED, COMPANYITS, REFILLED, CARTRIDGE,...            1      2   \n",
              "1  [not, like, writing, pen, pen, not, move, smoo...            1      2   \n",
              "2  [recieved, different, print, handle, scissors,...            1      2   \n",
              "3  [SEE, UPDATES, BELOWOriginal, Comment, frustra...            1      2   \n",
              "4  [still, not, understand, print, CD, bin, insid...            1      2   \n",
              "5  [Printer, died, watchingsad, really, really, n...            1      2   \n",
              "6  [really, excited, pay, dollar, remanufactured,...            1      2   \n",
              "7  [bought, particular, printer, got, good, revie...            1      2   \n",
              "8  [battery, falsely, advertised, retailer, repla...            1      2   \n",
              "9  [printer, came, without, usb, cable, can, not,...            1      2   \n",
              "\n",
              "                                          embeddings  \\\n",
              "0  [-0.10411242, 0.09739238, 0.10575975, 0.047679...   \n",
              "1  [-0.16601361, 0.12954007, -0.02997564, 0.14178...   \n",
              "2  [-0.17889404, 0.13225716, -0.0023766342, 0.141...   \n",
              "3  [-0.17457914, 0.11600011, -0.0072606727, 0.139...   \n",
              "4  [-0.17827804, 0.11349467, -0.009957709, 0.1409...   \n",
              "5  [-0.16731106, 0.11665142, -0.0127215665, 0.137...   \n",
              "6  [-0.17504133, 0.119549975, -0.010930842, 0.136...   \n",
              "7  [-0.18919432, 0.11898526, -0.017961523, 0.1430...   \n",
              "8  [-0.17931841, 0.12183528, -0.02442301, 0.13780...   \n",
              "9  [-0.18437353, 0.102645345, -0.02508545, 0.1488...   \n",
              "\n",
              "                                   embeddings_top_10  \n",
              "0  [-0.13574219, 0.119140625, 0.25390625, 0.04492...  \n",
              "1  [0.07910156, -0.0050354004, 0.111816406, 0.212...  \n",
              "2  [-0.27539062, -0.02331543, -0.068359375, 0.141...  \n",
              "3  [-0.026977539, 0.067871094, 0.106933594, 0.053...  \n",
              "4  [-0.22558594, -0.01953125, 0.09082031, 0.23730...  \n",
              "5  [-0.08251953, 0.12988281, 0.18945312, 0.03125,...  \n",
              "6  [0.07910156, -0.0050354004, 0.111816406, 0.212...  \n",
              "7  [0.07910156, -0.0050354004, 0.111816406, 0.212...  \n",
              "8  [-0.2421875, 0.14550781, 0.026855469, 0.007598...  \n",
              "9  [-0.2421875, 0.14550781, 0.026855469, 0.007598...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94f05f7f-1203-4679-9940-995b67e8c60c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>label</th>\n",
              "      <th>embeddings</th>\n",
              "      <th>embeddings_top_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[GOT, BURNED, COMPANYITS, REFILLED, CARTRIDGE,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.10411242, 0.09739238, 0.10575975, 0.047679...</td>\n",
              "      <td>[-0.13574219, 0.119140625, 0.25390625, 0.04492...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[not, like, writing, pen, pen, not, move, smoo...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.16601361, 0.12954007, -0.02997564, 0.14178...</td>\n",
              "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[recieved, different, print, handle, scissors,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.17889404, 0.13225716, -0.0023766342, 0.141...</td>\n",
              "      <td>[-0.27539062, -0.02331543, -0.068359375, 0.141...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[SEE, UPDATES, BELOWOriginal, Comment, frustra...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.17457914, 0.11600011, -0.0072606727, 0.139...</td>\n",
              "      <td>[-0.026977539, 0.067871094, 0.106933594, 0.053...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[still, not, understand, print, CD, bin, insid...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.17827804, 0.11349467, -0.009957709, 0.1409...</td>\n",
              "      <td>[-0.22558594, -0.01953125, 0.09082031, 0.23730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[Printer, died, watchingsad, really, really, n...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.16731106, 0.11665142, -0.0127215665, 0.137...</td>\n",
              "      <td>[-0.08251953, 0.12988281, 0.18945312, 0.03125,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[really, excited, pay, dollar, remanufactured,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.17504133, 0.119549975, -0.010930842, 0.136...</td>\n",
              "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[bought, particular, printer, got, good, revie...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.18919432, 0.11898526, -0.017961523, 0.1430...</td>\n",
              "      <td>[0.07910156, -0.0050354004, 0.111816406, 0.212...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[battery, falsely, advertised, retailer, repla...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.17931841, 0.12183528, -0.02442301, 0.13780...</td>\n",
              "      <td>[-0.2421875, 0.14550781, 0.026855469, 0.007598...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[printer, came, without, usb, cable, can, not,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.18437353, 0.102645345, -0.02508545, 0.1488...</td>\n",
              "      <td>[-0.2421875, 0.14550781, 0.026855469, 0.007598...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94f05f7f-1203-4679-9940-995b67e8c60c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94f05f7f-1203-4679-9940-995b67e8c60c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94f05f7f-1203-4679-9940-995b67e8c60c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d21c705-78fb-44fc-b7a9-38cc27524721\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d21c705-78fb-44fc-b7a9-38cc27524721')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d21c705-78fb-44fc-b7a9-38cc27524721 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_data"
            }
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3min 18s (started: 2025-02-13 23:11:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# also extract word embeddings\n",
        "def extract_embeddings(text, w2v_model, topn=None):\n",
        "    word_embeddings = [w2v_model[word] for word in text if word in w2v_model]\n",
        "    if topn is not None:\n",
        "      # For top10 concat, used further\n",
        "        if len(word_embeddings) < topn:\n",
        "            padding = [np.zeros(w2v_model.vector_size) for _ in range(topn - len(word_embeddings))]\n",
        "            word_embeddings.extend(padding)\n",
        "        elif len(word_embeddings) > topn:\n",
        "            word_embeddings = word_embeddings[:topn]\n",
        "        word_embeddings = np.concatenate(word_embeddings, axis=0)\n",
        "    else:\n",
        "        if len(word_embeddings) == 0:\n",
        "            word_embeddings = np.zeros(w2v_model.vector_size)\n",
        "        else:\n",
        "            word_embeddings = np.mean(word_embeddings, axis=0)\n",
        "\n",
        "    return word_embeddings\n",
        "\n",
        "\n",
        "# Preprocess data and generate word2vec embeddings Avg and top 10\n",
        "balanced_data[\"embeddings\"] = balanced_data[\"review_body\"].apply(lambda text: extract_embeddings(text, google_pretrained_model, topn=None))\n",
        "\n",
        "# Drop rows with NaN embeddings\n",
        "balanced_data.dropna(subset=[\"embeddings\"], inplace=True)\n",
        "balanced_data[\"embeddings_top_10\"] = balanced_data[\"review_body\"].apply(lambda text: extract_embeddings(text, google_pretrained_model, topn=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auiV1jJEhL6X",
        "outputId": "8fb5e0ee-f38f-402d-824d-29c8823436ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 31 s (started: 2025-02-13 23:14:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Ternary class model\n",
        "Reference:\n",
        "- https://stackoverflow.com/questions/41066582/python-save-pandas-data-frame-to-parquet-file"
      ],
      "metadata": {
        "id": "1nKBz-Bxtto9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the data type of the 'embeddings' column to float32\n",
        "balanced_data[\"embeddings\"] = balanced_data[\"embeddings\"].apply(lambda x: x.astype(np.float32) if isinstance(x, np.ndarray) else x)\n",
        "balanced_data[\"embeddings_top_10\"] = balanced_data[\"embeddings_top_10\"].apply(lambda x: x.astype(np.float32) if isinstance(x, np.ndarray) else x)\n",
        "\n",
        "balanced_data.to_parquet(\"amazon_reviews_balanced_ternary.parquet\", engine=\"pyarrow\", index=False)\n",
        "print(\"Dataset saved as 'amazon_reviews_balanced_ternary.parquet'\")\n",
        "\n",
        "# # TO LOAD PARQUET DATA:\n",
        "# parquet_balanced_data = pd.read_parquet(\"amazon_reviews_balanced.parquet\", engine=\"pyarrow\")\n",
        "# print(parquet_balanced_data.head())\n",
        "# print(f\"Total rows in dataset: {len(parquet_balanced_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V_fRh9Ctxry",
        "outputId": "22a2e69d-b32c-4850-a3a9-0ea7f0161209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as 'amazon_reviews_balanced_ternary.parquet'\n",
            "time: 42 s (started: 2025-02-13 23:15:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset"
      ],
      "metadata": {
        "id": "unj8UtFf3wGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "balanced_data = balanced_data.dropna(subset=['review_body', 'label'])\n",
        "train_df, test_df = train_test_split(balanced_data, test_size=ConfigValues.TEST_SPLIT, random_state=ConfigValues.RANDOM_STATE_VALUE, stratify=balanced_data[\"label\"])"
      ],
      "metadata": {
        "id": "1msCF9Vb3y_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe57e279-d0bb-44d1-b50a-173d38a33896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 251 ms (started: 2025-02-13 23:16:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings:\n",
        "Reference:\n",
        "- https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html\n",
        "- https://www.kaggle.com/code/bavalpreet26/word2vec-pretrained\n",
        "- https://stackabuse.com/implementing-word2vec-with-gensim-library-in-python/\n",
        "\n",
        "\n",
        "\n",
        "## (a) Load Pretrained Word2Vec"
      ],
      "metadata": {
        "id": "X37e8yNL4SNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# verify pretrained model examples\n",
        "print(\"google model: \", google_pretrained_model)\n",
        "print(google_pretrained_model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])[0])\n",
        "print(\"Similarity between 'excellent' and 'outstanding':\", google_pretrained_model.similarity('excellent', 'outstanding'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6dD7jZ1oDL1",
        "outputId": "43770fc7-0975-4897-a074-a35f6ef9d55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google model:  KeyedVectors<vector_size=300, 3000000 keys>\n",
            "('queen', 0.7118193507194519)\n",
            "Similarity between 'excellent' and 'outstanding': 0.55674857\n",
            "time: 219 ms (started: 2025-02-13 23:16:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional tests on pretrained model"
      ],
      "metadata": {
        "id": "-ncg__wCGuP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for more examples\n",
        "print(google_pretrained_model.most_similar(positive=[\"paris\", \"berlin\"], negative=[\"france\"])[0])\n",
        "print(\"Similarity between 'excellent' and 'outstanding':\", google_pretrained_model.similarity('student', 'university'))"
      ],
      "metadata": {
        "id": "-t8XV2UlFXUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e5a57c-6d49-4f9b-ab01-2c0f3aee2f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('kunst', 0.41797778010368347)\n",
            "Similarity between 'excellent' and 'outstanding': 0.60054\n",
            "time: 103 ms (started: 2025-02-13 23:16:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete pretrained model - handle ram, for now, DONT DELETE\n",
        "# del google_pretrained_model"
      ],
      "metadata": {
        "id": "3LZ8QmqKGVS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ad4c54-16b2-4578-df41-f3f3a8793f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 421 µs (started: 2025-02-13 07:40:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b) Custom Word2Vec Model"
      ],
      "metadata": {
        "id": "wQehH40Oy7Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_w2v = train_df['review_body'].tolist()\n",
        "print(\"Sample tokenized sentences:\", sentences_w2v[:5])\n",
        "\n",
        "# Word2Vec model training\n",
        "custom_w2v_model = Word2Vec(sentences_w2v, vector_size=W2VConfigValues.EMBEDDING_SIZE, window=W2VConfigValues.WINDOW_SIZE, min_count=W2VConfigValues.MIN_WORD_COUNT, workers=4)\n",
        "custom_w2v_model.save(\"custom_word2vec.model\")\n",
        "\n",
        "try:\n",
        "    print(\"King : Man :: Woman : \", custom_w2v_model.wv.most_similar(positive=['king', 'woman'], negative=['man'])[0])\n",
        "    print(\"Similarity between 'excellent' and 'outstanding': \", custom_w2v_model.wv.similarity('excellent', 'outstanding'))\n",
        "except KeyError as e:\n",
        "    print(f\"Word not in vocabulary: {e}\")"
      ],
      "metadata": {
        "id": "dYZUT6X2y_s6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e631bf3b-0577-4462-d8e8-4bfd768a2be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample tokenized sentences: [['excellent', 'product', 'Inkoneram', 'company', 'use'], ['Came', 'quickly', 'good', 'leaving', 'note', 'pinning', 'reminder', 'Kids', 'love', 'jot', 'note', 'dry', 'erase', 'part'], ['fountain', 'pen', 'buyer', 'like', 'not', 'buy', 'pen', 'without', 'knowing', 'nib', 'size', 'Every', 'supplier', 'Amazon', 'one', 'found', 'true', 'every', 'Germansounding', 'cigarshaped', 'pen', 'they', 'are', 'currently', 'selling', 'advice', 'sell', 'Lamywidth', 'F', 'fine', 'nib', 'desirable', 'size', 'limited', 'competition'], ['Ordered', 'keep', 'Visor', 'belt', 'clip', 'hold', 'belt', 'nicely', 'bend', 'squat', 'Visor', 'fall', 'belt', 'clipI', 'since', 'bought', 'small', 'leather', 'pouch', 'hold', 'Visor', 'belt', 'work', 'great'], ['printing', 'job', 'find', 'ECO', 'Ink', 'good', 'original', 'Dell', 'Series', 'ink', 'problem', 'printer', 'constantly', 'telling', 'ink', 'low', 'run', 'fact', 'installed', 'new', 'cartridge', 'use', 'printer', 'personal', 'use']]\n",
            "King : Man :: Woman : ('lady' , 0.6125918626785279)\n",
            "Similarity between 'excellent' and 'outstanding': 0.37514123\n",
            "time: 30.6 s (started: 2025-02-13 23:16:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for more examples\n",
        "try:\n",
        "  print(\"Custom W2V Model ===> boat : car :: wheel : \",custom_w2v_model.wv.most_similar(positive=[\"boat\", \"car\"], negative=[\"wheel\"])[0])\n",
        "  print(\"Custom W2V Model ===> Similarity between 'student' and 'university':\", custom_w2v_model.wv.similarity('student', 'university'))\n",
        "except KeyError as e:\n",
        "    print(f\"Word not in vocabulary: {e}\")"
      ],
      "metadata": {
        "id": "ZB02JnPP1k4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33581565-97d1-4cc8-b58d-9c1201455d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom W2V Model ===> boat : car :: wheel : ('road' , 06838219704654968)\n",
            "Custom W2V Model ===> Similarity between 'student' and 'university':0.69874583\n",
            "time: 535 µs (started: 2025-02-13 23:16:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "1. **Pretrained \"word2vec-google-news-300\" Model:**\n",
        "   - this model has been pretrained on a vast corpus, which shows strong generalization and the ability to capture a wide range of semantic relationships across different domains.\n",
        "   - Does not capture domain-specific relationships as effectively as models trained on specialized data.\n",
        "\n",
        "2. **Custom-trained Word2Vec Model:**\n",
        "   - My custom model excels at capturing domain-specific relationships when trained on specialized data.\n",
        "   - But it struggles with tasks outside its domain, and embedding quality depends on the size and representativeness of the training dataset.\n",
        "\n",
        "\n",
        "- The semantic similarity score is higher for the pretrained model compared to the custom model. This indicates that the pretrained model is better at encoding semantic similarities between words.\n",
        "\n",
        "- The custom Word2Vec model, which was trained on the provided dataset, may not have had access to as diverse and extensive a corpus as the pretrained model. This can lead to limitations in its ability to generalize and capture nuanced semantic relationships.\n"
      ],
      "metadata": {
        "id": "4hi5vhFkp6Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIMPLE MODELS\n",
        "\n",
        "Calculate Avg W2V Features\n"
      ],
      "metadata": {
        "id": "val9y6fGqGw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg_w2v(tokens, model, embedding_size=W2VConfigValues.EMBEDDING_SIZE):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in model:\n",
        "            vectors.append(model[token])\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(embedding_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "# For Google's model\n",
        "balanced_data[\"w2v_google\"] = balanced_data[\"review_body\"].apply(\n",
        "    lambda x: get_avg_w2v(x, google_pretrained_model)\n",
        ")\n",
        "\n",
        "# For custom model\n",
        "balanced_data[\"w2v_custom\"] = balanced_data[\"review_body\"].apply(\n",
        "    lambda x: get_avg_w2v(x, custom_w2v_model.wv)\n",
        ")"
      ],
      "metadata": {
        "id": "YJQppiuw7-OQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a2ecb3-03eb-4ec8-a27b-613b43f53d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 38 s (started: 2025-02-13 23:16:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Word2Vec features - pretrained and custom models\n",
        "X_google = np.stack(balanced_data[\"w2v_google\"].values)\n",
        "X_custom = np.stack(balanced_data[\"w2v_custom\"].values)\n",
        "y = balanced_data[\"label\"].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILQcfjAg1Fnk",
        "outputId": "f306557c-0ae0-4a99-dc10-89ca8ab87020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 746 ms (started: 2025-02-13 23:17:23 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Features Vectorization\n"
      ],
      "metadata": {
        "id": "rjSaOgMs8X5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf-idf comparison from assignment 1\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=ConfigValues.MAX_TFIDF_FEATURES)\n",
        "tfidf_features = tfidf.fit_transform(balanced_data[\"review_body\"].apply(\" \".join))"
      ],
      "metadata": {
        "id": "OelZdhMeqTDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f77e942-97f6-4f64-f90a-5719e47cdd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.18 s (started: 2025-02-13 23:17:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split for all features"
      ],
      "metadata": {
        "id": "EuJM_PgVAdvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split all feature sets for both pretrained &custom models\n",
        "\n",
        "X_google_train, X_google_test, y_train, y_test = train_test_split(\n",
        "    X_google, y, test_size=ConfigValues.TEST_SPLIT, random_state=ConfigValues.RANDOM_STATE_VALUE\n",
        ")\n",
        "X_custom_train, X_custom_test, _, _ = train_test_split(\n",
        "    X_custom, y, test_size=ConfigValues.TEST_SPLIT, random_state=ConfigValues.RANDOM_STATE_VALUE\n",
        ")\n",
        "X_tfidf_train, X_tfidf_test, _, _ = train_test_split(\n",
        "    tfidf_features, y, test_size=ConfigValues.TEST_SPLIT, random_state=ConfigValues.RANDOM_STATE_VALUE\n",
        ")"
      ],
      "metadata": {
        "id": "MmoimsHfAgmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ad7feb-1a68-48d9-a0a9-8cde3ccb26f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 346 ms (started: 2025-02-13 23:17:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train models & evaluate"
      ],
      "metadata": {
        "id": "PrnEcjA6A6pY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#helper fun to train both perceptron + svm\n",
        "def train_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    return model.score(X_test, y_test)\n",
        "\n",
        "perceptron = Perceptron()\n",
        "svm = LinearSVC()"
      ],
      "metadata": {
        "id": "dcvMXeJLA9AZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b3479d-d261-4f9a-e363-9e2313aa18c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 460 µs (started: 2025-02-13 23:17:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Perceptron"
      ],
      "metadata": {
        "id": "_ehDXh3d8DYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google News W2V\n",
        "p_acc_google = train_evaluate_model(perceptron, X_google_train, X_google_test, y_train, y_test)\n",
        "\n",
        "# Custom W2V\n",
        "p_acc_custom = train_evaluate_model(perceptron, X_custom_train, X_custom_test, y_train, y_test)\n",
        "\n",
        "# TF-IDF (from HW1)\n",
        "p_acc_tfidf = train_evaluate_model(perceptron, X_tfidf_train, X_tfidf_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "hQo1KOguA-TK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea03140e-fecc-42e0-edae-1b111e0b16d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.3 s (started: 2025-02-13 23:17:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) SVM"
      ],
      "metadata": {
        "id": "kHMoBxPcqTxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google News W2V\n",
        "s_acc_google = train_evaluate_model(svm, X_google_train, X_google_test, y_train, y_test)\n",
        "\n",
        "# Custom W2V\n",
        "s_acc_custom = train_evaluate_model(svm, X_custom_train, X_custom_test, y_train, y_test)\n",
        "\n",
        "# TF-IDF (from HW1)\n",
        "s_acc_tfidf = train_evaluate_model(svm, X_tfidf_train, X_tfidf_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "fKpRIYiFqXe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6327bd15-1c62-4a8c-c670-6aaf98aca5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10min 8s (started: 2025-02-13 23:17:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results for comparison\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Feature Type\": [\"Google W2V\", \"Custom W2V\", \"TF-IDF\"],\n",
        "    \"Perceptron\": [p_acc_google, p_acc_custom, p_acc_tfidf],\n",
        "    \"SVM\": [s_acc_google, s_acc_custom, s_acc_tfidf]\n",
        "})\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "id": "pB6xklhKBKaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d379f067-9a5e-4ca6-cc44-f96c6641814f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature Type  Perceptron       SVM\n",
            "0   Google W2V    0.593336  0.664719\n",
            "1   Custom W2V    0.660576  0.692075\n",
            "2       TF-IDF    0.669322  0.726016\n",
            "time: 5.64 ms (started: 2025-02-13 23:27:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis and Conclusions\n",
        "\n",
        "- **Pretrained W2V Performance:** Gives deceent baseline results due to rich semantic information from massive training data.\n",
        "\n",
        "- **Custom W2V Performance:** May underperform compared to pretrained due to smaller domain-specific data, but could capture niche patterns.\n",
        "\n",
        "- **TF-IDF Performance:** Likely highest accuracy but lacks semantic understanding. Might outperform custom W2V if domain is very different from pretrained data.\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "- **Pretrained embeddings** generally outperform others when semantic relationships are crucial\n",
        "\n",
        "- **Custom embeddings** need sufficient domain-specific data to be effective\n",
        "\n",
        "- **TF-IDF** remains competitive for simple classification tasks\n",
        "\n"
      ],
      "metadata": {
        "id": "nCpBSaBBBS_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N8jCCsvw0_cV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch & FNN\n",
        "\n",
        "Reference:\n",
        "- http://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
        "- https://machinelearningmastery.com/building-multilayer-perceptron-models-in-pytorch/\n",
        "- https://discuss.pytorch.org/t/how-to-create-mlp-model-with-arbitrary-number-of-hidden-layers/13124/6\n",
        "- https://www.tutorialspoint.com/how-to-compute-the-cross-entropy-loss-between-input-and-target-tensors-in-pytorch"
      ],
      "metadata": {
        "id": "FcLv14UkG46R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refernece from prev embeddings calc\n",
        "def get_top10_concat(tokens, model, embedding_size=W2VConfigValues.EMBEDDING_SIZE, topn=10):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in model:\n",
        "            vectors.append(model[token])\n",
        "        if len(vectors) == topn:\n",
        "            break\n",
        "    # If fewer than topn vectors are found, pad with zeros\n",
        "    if len(vectors) < topn:\n",
        "        pad_vector = np.zeros(embedding_size)\n",
        "        vectors.extend([pad_vector] * (topn - len(vectors)))\n",
        "    return np.concatenate(vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qbb7lodA9nl",
        "outputId": "78f16cc8-db53-4037-a8bf-fef0ff31fb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 541 µs (started: 2025-02-13 23:27:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained model top 10 concat features\n",
        "balanced_data[\"w2v_google_top10\"] = balanced_data[\"review_body\"].apply(\n",
        "    lambda tokens: get_top10_concat(tokens, google_pretrained_model, embedding_size=W2VConfigValues.EMBEDDING_SIZE, topn=10)\n",
        ")\n",
        "\n",
        "# custom model top 10 concat features\n",
        "balanced_data[\"w2v_custom_top10\"] = balanced_data[\"review_body\"].apply(\n",
        "    lambda tokens: get_top10_concat(tokens, custom_w2v_model.wv, embedding_size=W2VConfigValues.EMBEDDING_SIZE, topn=10)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCOVH-lRA_JK",
        "outputId": "b2801542-860e-463b-c53b-996a24c0a65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12 s (started: 2025-02-13 23:27:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "AtvkzMlJ97de",
        "outputId": "146427e5-544f-4ca4-8321-e9c0ef3873b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_body  star_rating  label  \\\n",
              "0  [GOT, BURNED, COMPANYITS, REFILLED, CARTRIDGE,...            1      2   \n",
              "1  [not, like, writing, pen, pen, not, move, smoo...            1      2   \n",
              "2  [recieved, different, print, handle, scissors,...            1      2   \n",
              "3  [SEE, UPDATES, BELOWOriginal, Comment, frustra...            1      2   \n",
              "4  [still, not, understand, print, CD, bin, insid...            1      2   \n",
              "5  [Printer, died, watchingsad, really, really, n...            1      2   \n",
              "6  [really, excited, pay, dollar, remanufactured,...            1      2   \n",
              "7  [bought, particular, printer, got, good, revie...            1      2   \n",
              "8  [battery, falsely, advertised, retailer, repla...            1      2   \n",
              "9  [printer, came, without, usb, cable, can, not,...            1      2   \n",
              "\n",
              "                                          embeddings  \\\n",
              "0  [-2.2888184e-05, -0.05861759, 0.096069336, 0.1...   \n",
              "1  [0.027827336, -0.0028733474, -0.026722835, 0.0...   \n",
              "2  [0.012795342, -0.05362956, -0.056148104, 0.070...   \n",
              "3  [0.033777338, 0.029676009, -0.03273879, 0.0796...   \n",
              "4  [0.061248373, 0.032459553, 0.0037813315, 0.091...   \n",
              "5  [0.038636904, 0.014158094, -0.036014453, 0.134...   \n",
              "6  [0.007715296, 0.036310267, 0.028971354, 0.0489...   \n",
              "7  [0.060222354, 0.053037915, -0.02220331, 0.1071...   \n",
              "8  [0.027699789, 0.03033956, 0.031600952, 0.05327...   \n",
              "9  [0.011201558, 0.05953819, -0.0723114, 0.081193...   \n",
              "\n",
              "                                   embeddings_top_10  \\\n",
              "0  [-0.122558594, -0.123046875, 0.12060547, 0.085...   \n",
              "1  [0.08496094, -0.095214844, 0.119140625, 0.1118...   \n",
              "2  [0.015136719, -0.15136719, -0.11376953, -0.122...   \n",
              "3  [-0.061523438, -0.05908203, -0.15136719, 0.197...   \n",
              "4  [0.23242188, 0.020996094, 0.028686523, 0.05126...   \n",
              "5  [0.23632812, -0.095214844, -0.083496094, 0.208...   \n",
              "6  [0.096191406, -0.028686523, -0.10839844, 0.145...   \n",
              "7  [0.16699219, -0.05419922, -0.087402344, 0.0196...   \n",
              "8  [-0.017089844, 0.27539062, 0.35742188, -0.4804...   \n",
              "9  [0.13671875, 0.016235352, -0.24023438, 0.26562...   \n",
              "\n",
              "                                          w2v_google  \\\n",
              "0  [-2.2888184e-05, -0.05861759, 0.096069336, 0.1...   \n",
              "1  [0.027827336, -0.0028733474, -0.026722835, 0.0...   \n",
              "2  [0.012795342, -0.05362956, -0.056148104, 0.070...   \n",
              "3  [0.033777338, 0.029676009, -0.03273879, 0.0796...   \n",
              "4  [0.061248373, 0.032459553, 0.0037813315, 0.091...   \n",
              "5  [0.038636904, 0.014158094, -0.036014453, 0.134...   \n",
              "6  [0.007715296, 0.036310267, 0.028971354, 0.0489...   \n",
              "7  [0.060222354, 0.053037915, -0.02220331, 0.1071...   \n",
              "8  [0.027699789, 0.03033956, 0.031600952, 0.05327...   \n",
              "9  [0.011201558, 0.05953819, -0.0723114, 0.081193...   \n",
              "\n",
              "                                          w2v_custom  \\\n",
              "0  [0.109059446, 0.4693036, 0.273149, 0.18213537,...   \n",
              "1  [-0.23718467, 0.2352095, -0.5729257, 0.1161454...   \n",
              "2  [0.48534787, -0.22741744, -0.14464456, 0.23659...   \n",
              "3  [0.3214133, -0.29038614, -0.27273834, -0.03934...   \n",
              "4  [0.01903169, -0.33039725, 0.08728423, 0.033782...   \n",
              "5  [0.51463646, -0.3118997, -0.477293, -0.0710141...   \n",
              "6  [-0.045897555, -0.13081855, -0.6079834, 0.1627...   \n",
              "7  [0.05092244, -0.2995325, -0.4813974, -0.074036...   \n",
              "8  [-0.068040684, 0.001074098, 0.11187974, 0.1953...   \n",
              "9  [-0.23134919, -0.115903944, -0.068366356, 0.57...   \n",
              "\n",
              "                                    w2v_google_top10  \\\n",
              "0  [-0.12255859375, -0.123046875, 0.12060546875, ...   \n",
              "1  [0.08496094, -0.095214844, 0.119140625, 0.1118...   \n",
              "2  [0.015136719, -0.15136719, -0.11376953, -0.122...   \n",
              "3  [-0.061523438, -0.05908203, -0.15136719, 0.197...   \n",
              "4  [0.23242188, 0.020996094, 0.028686523, 0.05126...   \n",
              "5  [0.23632812, -0.095214844, -0.083496094, 0.208...   \n",
              "6  [0.096191406, -0.028686523, -0.10839844, 0.145...   \n",
              "7  [0.16699219, -0.05419922, -0.087402344, 0.0196...   \n",
              "8  [-0.017089844, 0.27539062, 0.35742188, -0.4804...   \n",
              "9  [0.13671875, 0.016235352, -0.24023438, 0.26562...   \n",
              "\n",
              "                                    w2v_custom_top10  \n",
              "0  [0.1417940855026245, 0.7407890558242798, 0.665...  \n",
              "1  [-0.35944247, -1.7913938, 0.070307925, 0.44187...  \n",
              "2  [0.12648556, 1.0873816, -0.006608068, 0.120021...  \n",
              "3  [0.14472677, 0.42426637, 0.3546991, 0.05342230...  \n",
              "4  [-0.019619193, -1.9344671, 0.19588223, 0.72333...  \n",
              "5  [0.2527238, 0.12207531, -0.9822222, 0.45959377...  \n",
              "6  [-0.788997, -0.49314982, -0.17793937, 1.030042...  \n",
              "7  [0.64812845, 0.79431665, 0.15443023, -1.663465...  \n",
              "8  [0.6522995, 0.63686657, 1.6811428, 0.36491668,...  \n",
              "9  [0.8007911, 0.10778725, -1.5054251, 1.3753093,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f25d23da-0993-4cfe-815f-b9ae1e49d26c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_body</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>label</th>\n",
              "      <th>embeddings</th>\n",
              "      <th>embeddings_top_10</th>\n",
              "      <th>w2v_google</th>\n",
              "      <th>w2v_custom</th>\n",
              "      <th>w2v_google_top10</th>\n",
              "      <th>w2v_custom_top10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[GOT, BURNED, COMPANYITS, REFILLED, CARTRIDGE,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[-2.2888184e-05, -0.05861759, 0.096069336, 0.1...</td>\n",
              "      <td>[-0.122558594, -0.123046875, 0.12060547, 0.085...</td>\n",
              "      <td>[-2.2888184e-05, -0.05861759, 0.096069336, 0.1...</td>\n",
              "      <td>[0.109059446, 0.4693036, 0.273149, 0.18213537,...</td>\n",
              "      <td>[-0.12255859375, -0.123046875, 0.12060546875, ...</td>\n",
              "      <td>[0.1417940855026245, 0.7407890558242798, 0.665...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[not, like, writing, pen, pen, not, move, smoo...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.027827336, -0.0028733474, -0.026722835, 0.0...</td>\n",
              "      <td>[0.08496094, -0.095214844, 0.119140625, 0.1118...</td>\n",
              "      <td>[0.027827336, -0.0028733474, -0.026722835, 0.0...</td>\n",
              "      <td>[-0.23718467, 0.2352095, -0.5729257, 0.1161454...</td>\n",
              "      <td>[0.08496094, -0.095214844, 0.119140625, 0.1118...</td>\n",
              "      <td>[-0.35944247, -1.7913938, 0.070307925, 0.44187...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[recieved, different, print, handle, scissors,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.012795342, -0.05362956, -0.056148104, 0.070...</td>\n",
              "      <td>[0.015136719, -0.15136719, -0.11376953, -0.122...</td>\n",
              "      <td>[0.012795342, -0.05362956, -0.056148104, 0.070...</td>\n",
              "      <td>[0.48534787, -0.22741744, -0.14464456, 0.23659...</td>\n",
              "      <td>[0.015136719, -0.15136719, -0.11376953, -0.122...</td>\n",
              "      <td>[0.12648556, 1.0873816, -0.006608068, 0.120021...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[SEE, UPDATES, BELOWOriginal, Comment, frustra...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.033777338, 0.029676009, -0.03273879, 0.0796...</td>\n",
              "      <td>[-0.061523438, -0.05908203, -0.15136719, 0.197...</td>\n",
              "      <td>[0.033777338, 0.029676009, -0.03273879, 0.0796...</td>\n",
              "      <td>[0.3214133, -0.29038614, -0.27273834, -0.03934...</td>\n",
              "      <td>[-0.061523438, -0.05908203, -0.15136719, 0.197...</td>\n",
              "      <td>[0.14472677, 0.42426637, 0.3546991, 0.05342230...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[still, not, understand, print, CD, bin, insid...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.061248373, 0.032459553, 0.0037813315, 0.091...</td>\n",
              "      <td>[0.23242188, 0.020996094, 0.028686523, 0.05126...</td>\n",
              "      <td>[0.061248373, 0.032459553, 0.0037813315, 0.091...</td>\n",
              "      <td>[0.01903169, -0.33039725, 0.08728423, 0.033782...</td>\n",
              "      <td>[0.23242188, 0.020996094, 0.028686523, 0.05126...</td>\n",
              "      <td>[-0.019619193, -1.9344671, 0.19588223, 0.72333...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[Printer, died, watchingsad, really, really, n...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.038636904, 0.014158094, -0.036014453, 0.134...</td>\n",
              "      <td>[0.23632812, -0.095214844, -0.083496094, 0.208...</td>\n",
              "      <td>[0.038636904, 0.014158094, -0.036014453, 0.134...</td>\n",
              "      <td>[0.51463646, -0.3118997, -0.477293, -0.0710141...</td>\n",
              "      <td>[0.23632812, -0.095214844, -0.083496094, 0.208...</td>\n",
              "      <td>[0.2527238, 0.12207531, -0.9822222, 0.45959377...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[really, excited, pay, dollar, remanufactured,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.007715296, 0.036310267, 0.028971354, 0.0489...</td>\n",
              "      <td>[0.096191406, -0.028686523, -0.10839844, 0.145...</td>\n",
              "      <td>[0.007715296, 0.036310267, 0.028971354, 0.0489...</td>\n",
              "      <td>[-0.045897555, -0.13081855, -0.6079834, 0.1627...</td>\n",
              "      <td>[0.096191406, -0.028686523, -0.10839844, 0.145...</td>\n",
              "      <td>[-0.788997, -0.49314982, -0.17793937, 1.030042...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[bought, particular, printer, got, good, revie...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.060222354, 0.053037915, -0.02220331, 0.1071...</td>\n",
              "      <td>[0.16699219, -0.05419922, -0.087402344, 0.0196...</td>\n",
              "      <td>[0.060222354, 0.053037915, -0.02220331, 0.1071...</td>\n",
              "      <td>[0.05092244, -0.2995325, -0.4813974, -0.074036...</td>\n",
              "      <td>[0.16699219, -0.05419922, -0.087402344, 0.0196...</td>\n",
              "      <td>[0.64812845, 0.79431665, 0.15443023, -1.663465...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[battery, falsely, advertised, retailer, repla...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.027699789, 0.03033956, 0.031600952, 0.05327...</td>\n",
              "      <td>[-0.017089844, 0.27539062, 0.35742188, -0.4804...</td>\n",
              "      <td>[0.027699789, 0.03033956, 0.031600952, 0.05327...</td>\n",
              "      <td>[-0.068040684, 0.001074098, 0.11187974, 0.1953...</td>\n",
              "      <td>[-0.017089844, 0.27539062, 0.35742188, -0.4804...</td>\n",
              "      <td>[0.6522995, 0.63686657, 1.6811428, 0.36491668,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[printer, came, without, usb, cable, can, not,...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.011201558, 0.05953819, -0.0723114, 0.081193...</td>\n",
              "      <td>[0.13671875, 0.016235352, -0.24023438, 0.26562...</td>\n",
              "      <td>[0.011201558, 0.05953819, -0.0723114, 0.081193...</td>\n",
              "      <td>[-0.23134919, -0.115903944, -0.068366356, 0.57...</td>\n",
              "      <td>[0.13671875, 0.016235352, -0.24023438, 0.26562...</td>\n",
              "      <td>[0.8007911, 0.10778725, -1.5054251, 1.3753093,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f25d23da-0993-4cfe-815f-b9ae1e49d26c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f25d23da-0993-4cfe-815f-b9ae1e49d26c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f25d23da-0993-4cfe-815f-b9ae1e49d26c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7886ac93-f705-4f52-a107-d61b44ffee1e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7886ac93-f705-4f52-a107-d61b44ffee1e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7886ac93-f705-4f52-a107-d61b44ffee1e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_data"
            }
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 49.6 ms (started: 2025-02-13 23:28:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n"
      ],
      "metadata": {
        "id": "UP1BTQt76LxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Heavey processing\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create dataLoader using features and labels.\n",
        "def create_dataloader(X, y, batch_size=64, shuffle=True):\n",
        "    X_tensor = torch.tensor(np.stack(X.values), dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
        "    dataset = TensorDataset(X_tensor, y_tensor)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "\n",
        "# 1 epoch pass\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device=device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataloader, device=device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ZYVBvW6OYv",
        "outputId": "5cf9771e-2533-4a16-f42d-11d77d8503c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 70.3 ms (started: 2025-02-13 21:13:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the MLP Model"
      ],
      "metadata": {
        "id": "AF7Q-GqRHnIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9wTFhFAHqqc",
        "outputId": "5f035c1e-d962-41db-c7c1-1921bcadadf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 744 µs (started: 2025-02-13 20:33:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training & eval\n",
        "def run_testcase(input_dim, hidden1, hidden2, output_dim, train_loader, test_loader, epochs=10, lr=0.001):\n",
        "    model = MLP(input_dim, hidden1, hidden2, output_dim).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
        "\n",
        "    acc = evaluate_model(model, test_loader, device)\n",
        "    return model, acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ul1UqSd_RbM",
        "outputId": "ba546e64-4301-4ef6-89bd-e42757ebbd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 931 µs (started: 2025-02-13 20:33:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCARDING BELOW CODE TO CREATE REUSABLE FUNCTIONS\n",
        "\n",
        "# # Binary Class\n",
        "# binary_data = balanced_data[balanced_data['label'].isin([1, 2])].copy()\n",
        "# # Split into train and test\n",
        "# X_bin_avg = binary_data['embeddings']  # For part (a) Avg w2v features\n",
        "# y_bin = binary_data['label'].replace({1: 0, 2: 1})  # Convert to 0/1 labels\n",
        "# X_train_bin_avg, X_test_bin_avg, y_train_bin, y_test_bin = train_test_split(\n",
        "#     X_bin_avg, y_bin, test_size=ConfigValues.TEST_SPLIT, random_state=seed, stratify=y_bin\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkQ3-155G8Iw",
        "outputId": "52d8c119-29e5-47f9-f4ed-ebae39653e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 192 ms (started: 2025-02-13 08:27:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCARDING BELOW CODE TO CREATE REUSABLE FUNCTIONS\n",
        "# # Ternary Classes\n",
        "# ternary_data = balanced_data.copy()\n",
        "# ternary_data['label'] = ternary_data['label'] - 1  # Map 1/2/3 → 0/1/2\n",
        "# # Split into train and test\n",
        "# X_tern_avg = ternary_data['embeddings']  # For part (a) Avg w2V features\n",
        "# y_tern = ternary_data['label']\n",
        "# X_train_tern_avg, X_test_tern_avg, y_train_tern, y_test_tern = train_test_split(\n",
        "#     X_tern_avg, y_tern, test_size=0.2, random_state=seed, stratify=y_tern\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-M7kUbfHCzS",
        "outputId": "f6814de2-c568-4b21-e6d9-87abe1dccf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 203 ms (started: 2025-02-13 08:27:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define PyTorch datasets and DataLoaders"
      ],
      "metadata": {
        "id": "kRnsj8OZHUh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCARDING BELOW CODE TO CREATE REUSABLE FUNCTIONS\n",
        "# # Create DataLoaders for average features\n",
        "# batch_size = 64\n",
        "# train_loader_bin_avg = create_dataloader(X_train_bin_avg, y_train_bin, batch_size=batch_size, shuffle=True)\n",
        "# test_loader_bin_avg  = create_dataloader(X_test_bin_avg, y_test_bin, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# train_loader_tern_avg = create_dataloader(X_train_tern_avg, y_train_tern, batch_size=batch_size, shuffle=True)\n",
        "# test_loader_tern_avg  = create_dataloader(X_test_tern_avg, y_test_tern, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "yOsnCPpU6OWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCARDING BELOW CODE TO CREATE REUSABLE FUNCTIONS\n",
        "# # For concatenated top 10 Word2Vec features\n",
        "# X_bin_concat = binary_data['embeddings_top_10']\n",
        "# X_tern_concat = ternary_data['embeddings_top_10']\n",
        "\n",
        "# X_train_bin_concat, X_test_bin_concat, y_train_bin_concat, y_test_bin_concat = train_test_split(\n",
        "#     X_bin_concat, y_bin, test_size=0.2, random_state=seed, stratify=y_bin\n",
        "# )\n",
        "\n",
        "# X_train_tern_concat, X_test_tern_concat, y_train_tern_concat, y_test_tern_concat = train_test_split(\n",
        "#     X_tern_concat, y_tern, test_size=0.2, random_state=seed, stratify=y_tern\n",
        "# )"
      ],
      "metadata": {
        "id": "sdVEW3x36OUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCARDING BELOW CODE TO CREATE REUSABLE FUNCTIONS\n",
        "# train_loader_bin_concat = create_dataloader(X_train_bin_concat, y_train_bin_concat, batch_size=batch_size, shuffle=True)\n",
        "# test_loader_bin_concat  = create_dataloader(X_test_bin_concat, y_test_bin_concat, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# train_loader_tern_concat = create_dataloader(X_train_tern_concat, y_train_tern_concat, batch_size=batch_size, shuffle=True)\n",
        "# test_loader_tern_concat  = create_dataloader(X_test_tern_concat, y_test_tern_concat, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "TiBH9T_X6OQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = {\n",
        "    # Part A - avg W2V\n",
        "    'Avg W2V Pretrained - Binary': {\n",
        "        'feature_col': 'w2v_google', 'task': 'binary', 'input_dim': 300},\n",
        "    'Avg W2V Pretrained - Ternary': {\n",
        "        'feature_col': 'w2v_google', 'task': 'ternary', 'input_dim': 300},\n",
        "    'Avg W2V Custom - Binary': {\n",
        "        'feature_col': 'w2v_custom', 'task': 'binary', 'input_dim': 300},\n",
        "    'Avg W2V Custom - Ternary': {\n",
        "        'feature_col': 'w2v_custom', 'task': 'ternary', 'input_dim': 300},\n",
        "    # PArt B - top 10 concat W2V\n",
        "    'Top10 W2V Pretrained - Binary': {\n",
        "        'feature_col': 'w2v_google_top10', 'task': 'binary', 'input_dim': 3000},\n",
        "    'Top10 W2V Pretrained - Ternary': {\n",
        "        'feature_col': 'w2v_google_top10', 'task': 'ternary', 'input_dim': 3000},\n",
        "    'Top10 W2V Custom - Binary': {\n",
        "        'feature_col': 'w2v_custom_top10', 'task': 'binary', 'input_dim': 3000},\n",
        "    'Top10 W2V Custom - Ternary': {\n",
        "        'feature_col': 'w2v_custom_top10', 'task': 'ternary', 'input_dim': 3000},\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzm3HUNG_oNW",
        "outputId": "c57a8aa6-3767-4b6a-c352-cb3a5cb4afcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 498 µs (started: 2025-02-13 20:33:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "results = {}\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# Loop over experiments\n",
        "for exp_name, config in experiments.items():\n",
        "    print(\"\\n--- Running Experiment:\", exp_name, \"---\")\n",
        "    feature_col = config['feature_col']\n",
        "    task = config['task']\n",
        "    input_dim = config['input_dim']\n",
        "\n",
        "    if task == 'binary':\n",
        "        data_subset = balanced_data[balanced_data['label'].isin([1, 2])].copy()\n",
        "        data_subset['binary_label'] = data_subset['label'].replace({1: 0, 2: 1})\n",
        "        X = data_subset[feature_col]\n",
        "        y = data_subset['binary_label']\n",
        "        output_dim = 2\n",
        "    else:\n",
        "        data_subset = balanced_data.copy()\n",
        "        # 1,2,3 becomes 0,1,2\n",
        "        data_subset['ternary_label'] = data_subset['label'] - 1\n",
        "        X = data_subset[feature_col]\n",
        "        y = data_subset['ternary_label']\n",
        "        output_dim = 3\n",
        "\n",
        "    # data split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=ConfigValues.TEST_SPLIT, random_state=seed, stratify=y)\n",
        "    train_loader = create_dataloader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = create_dataloader(X_test, y_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # run every exp case\n",
        "    _, accuracy = run_testcase(input_dim=input_dim, hidden1=50, hidden2=10,\n",
        "                                 output_dim=output_dim, train_loader=train_loader,\n",
        "                                 test_loader=test_loader, epochs=epochs, lr=0.001)\n",
        "    results[exp_name] = accuracy\n",
        "    print(f\"{exp_name} Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Q3IKaP_pAS",
        "outputId": "c4b1f7ec-dc7e-4b29-eb29-aab73704e9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Experiment: Avg W2V Pretrained - Binary ---\n",
            "Epoch 1/10, Loss: 0.4043\n",
            "Epoch 2/10, Loss: 0.3725\n",
            "Epoch 3/10, Loss: 0.3623\n",
            "Epoch 4/10, Loss: 0.3552\n",
            "Epoch 5/10, Loss: 0.3480\n",
            "Epoch 6/10, Loss: 0.3431\n",
            "Epoch 7/10, Loss: 0.3374\n",
            "Epoch 8/10, Loss: 0.3346\n",
            "Epoch 9/10, Loss: 0.3328\n",
            "Epoch 10/10, Loss: 0.3289\n",
            "Avg W2V Pretrained - Binary Accuracy: 0.8593\n",
            "\n",
            "--- Running Experiment: Avg W2V Pretrained - Ternary ---\n",
            "Epoch 1/10, Loss: 0.7935\n",
            "Epoch 2/10, Loss: 0.7568\n",
            "Epoch 3/10, Loss: 0.7460\n",
            "Epoch 4/10, Loss: 0.7381\n",
            "Epoch 5/10, Loss: 0.7318\n",
            "Epoch 6/10, Loss: 0.7272\n",
            "Epoch 7/10, Loss: 0.7236\n",
            "Epoch 8/10, Loss: 0.7208\n",
            "Epoch 9/10, Loss: 0.7183\n",
            "Epoch 10/10, Loss: 0.7160\n",
            "Avg W2V Pretrained - Ternary Accuracy: 0.6966\n",
            "\n",
            "--- Running Experiment: Avg W2V Custom - Binary ---\n",
            "Epoch 1/10, Loss: 0.3416\n",
            "Epoch 2/10, Loss: 0.3209\n",
            "Epoch 3/10, Loss: 0.3134\n",
            "Epoch 4/10, Loss: 0.3072\n",
            "Epoch 5/10, Loss: 0.3036\n",
            "Epoch 6/10, Loss: 0.3010\n",
            "Epoch 7/10, Loss: 0.2980\n",
            "Epoch 8/10, Loss: 0.2966\n",
            "Epoch 9/10, Loss: 0.2945\n",
            "Epoch 10/10, Loss: 0.2931\n",
            "Avg W2V Custom - Binary Accuracy: 0.8789\n",
            "\n",
            "--- Running Experiment: Avg W2V Custom - Ternary ---\n",
            "Epoch 1/10, Loss: 0.7311\n",
            "Epoch 2/10, Loss: 0.7065\n",
            "Epoch 3/10, Loss: 0.6990\n",
            "Epoch 4/10, Loss: 0.6941\n",
            "Epoch 5/10, Loss: 0.6904\n",
            "Epoch 6/10, Loss: 0.6869\n",
            "Epoch 7/10, Loss: 0.6852\n",
            "Epoch 8/10, Loss: 0.6826\n",
            "Epoch 9/10, Loss: 0.6810\n",
            "Epoch 10/10, Loss: 0.6794\n",
            "Avg W2V Custom - Ternary Accuracy: 0.7149\n",
            "\n",
            "--- Running Experiment: Top10 W2V Pretrained - Binary ---\n",
            "Epoch 1/10, Loss: 0.4717\n",
            "Epoch 2/10, Loss: 0.4250\n",
            "Epoch 3/10, Loss: 0.3953\n",
            "Epoch 4/10, Loss: 0.3673\n",
            "Epoch 5/10, Loss: 0.3445\n",
            "Epoch 6/10, Loss: 0.3240\n",
            "Epoch 7/10, Loss: 0.3069\n",
            "Epoch 8/10, Loss: 0.2926\n",
            "Epoch 9/10, Loss: 0.2781\n",
            "Epoch 10/10, Loss: 0.2682\n",
            "Top10 W2V Pretrained - Binary Accuracy: 0.8116\n",
            "\n",
            "--- Running Experiment: Top10 W2V Pretrained - Ternary ---\n",
            "Epoch 1/10, Loss: 0.8528\n",
            "Epoch 2/10, Loss: 0.8030\n",
            "Epoch 3/10, Loss: 0.7738\n",
            "Epoch 4/10, Loss: 0.7481\n",
            "Epoch 5/10, Loss: 0.7247\n",
            "Epoch 6/10, Loss: 0.7072\n",
            "Epoch 7/10, Loss: 0.6893\n",
            "Epoch 8/10, Loss: 0.6721\n",
            "Epoch 9/10, Loss: 0.6584\n",
            "Epoch 10/10, Loss: 0.6461\n",
            "Top10 W2V Pretrained - Ternary Accuracy: 0.6524\n",
            "\n",
            "--- Running Experiment: Top10 W2V Custom - Binary ---\n",
            "Epoch 1/10, Loss: 0.4428\n",
            "Epoch 2/10, Loss: 0.4083\n",
            "Epoch 3/10, Loss: 0.3912\n",
            "Epoch 4/10, Loss: 0.3750\n",
            "Epoch 5/10, Loss: 0.3613\n",
            "Epoch 6/10, Loss: 0.3487\n",
            "Epoch 7/10, Loss: 0.3363\n",
            "Epoch 8/10, Loss: 0.3265\n",
            "Epoch 9/10, Loss: 0.3170\n",
            "Epoch 10/10, Loss: 0.3075\n",
            "Top10 W2V Custom - Binary Accuracy: 0.8197\n",
            "\n",
            "--- Running Experiment: Top10 W2V Custom - Ternary ---\n",
            "Epoch 1/10, Loss: 0.8278\n",
            "Epoch 2/10, Loss: 0.7904\n",
            "Epoch 3/10, Loss: 0.7731\n",
            "Epoch 4/10, Loss: 0.7579\n",
            "Epoch 5/10, Loss: 0.7450\n",
            "Epoch 6/10, Loss: 0.7331\n",
            "Epoch 7/10, Loss: 0.7231\n",
            "Epoch 8/10, Loss: 0.7127\n",
            "Epoch 9/10, Loss: 0.7044\n",
            "Epoch 10/10, Loss: 0.6971\n",
            "Top10 W2V Custom - Ternary Accuracy: 0.6634\n",
            "time: 9min 4s (started: 2025-02-13 20:34:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(list(results.items()), columns=['Experiment', 'Accuracy'])\n",
        "print(\"\\nFinal Results:\\n\", results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uG4QeVW_wF9",
        "outputId": "082e553f-6459-438f-f30e-a732b5633b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Results:\n",
            "                        Experiment  Accuracy\n",
            "0     Avg W2V Pretrained - Binary  0.859334\n",
            "1    Avg W2V Pretrained - Ternary  0.696600\n",
            "2         Avg W2V Custom - Binary  0.878921\n",
            "3        Avg W2V Custom - Ternary  0.714872\n",
            "4   Top10 W2V Pretrained - Binary  0.811603\n",
            "5  Top10 W2V Pretrained - Ternary  0.652431\n",
            "6       Top10 W2V Custom - Binary  0.819683\n",
            "7      Top10 W2V Custom - Ternary  0.663398\n",
            "time: 2.78 ms (started: 2025-02-13 20:43:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qT71_Txu_wBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "\n",
        "Reference:\n",
        "- https://www.digitalocean.com/community/tutorials/writing-cnns-from-scratch-in-pytorch\n",
        "\n"
      ],
      "metadata": {
        "id": "sym2b0VGiZ9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ0SuGvgKetd",
        "outputId": "127c1052-ecb4-470b-9bca-1378c82c3549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 301 µs (started: 2025-02-13 23:35:53 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "bSIeyJKcFySH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ref from prev impl\n",
        "def get_sequence_embeddings(tokens, model, max_length=W2VConfigValues.MAX_LENGTH, embedding_size=W2VConfigValues.EMBEDDING_SIZE):\n",
        "    embeddings = []\n",
        "    for token in tokens[:max_length]:\n",
        "        if token in model.key_to_index:\n",
        "            embeddings.append(model[token])\n",
        "        else:\n",
        "            embeddings.append(np.zeros(embedding_size))\n",
        "    if len(embeddings) < max_length:\n",
        "        pad = [np.zeros(embedding_size)] * (max_length - len(embeddings))\n",
        "        embeddings.extend(pad)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "\n",
        "def prepare_loaders(data, text_column='sequence_embeddings', label_column='label', test_size=0.2, batch_size=16):\n",
        "    # stack embeddings\n",
        "    X = np.stack(data[text_column].values)\n",
        "    y = data[label_column].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "    # Convert arrays to tensors\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "    # Create TensorDatasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsXdIaBxFxKx",
        "outputId": "dfbe419e-d645-4436-b3a8-83ba3e86633d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.01 ms (started: 2025-02-13 23:38:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn model def\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim=W2VConfigValues.EMBEDDING_SIZE, num_classes=2):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=50, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(in_channels=50, out_channels=10, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.global_pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc = nn.Linear(10, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.relu1(self.conv1(x))\n",
        "        x = self.relu2(self.conv2(x))\n",
        "        x = self.global_pool(x).squeeze(-1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLQse97LF4TP",
        "outputId": "a9b5b6e0-4683-4b69-ea78-9e019f553f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 873 µs (started: 2025-02-13 23:39:35 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs, device):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def evaluate_model(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxNA9q_qF4RI",
        "outputId": "21f1cf03-0ec7-48e4-a684-dd484cbe3a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.03 ms (started: 2025-02-13 23:41:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for pretrained\n",
        "balanced_data['sequence_embeddings_google'] = balanced_data['review_body'].apply(\n",
        "    lambda x: get_sequence_embeddings(x, google_pretrained_model, max_length=50)\n",
        ")\n",
        "\n",
        "# for custom model\n",
        "balanced_data['sequence_embeddings_custom'] = balanced_data['review_body'].apply(\n",
        "    lambda x: get_sequence_embeddings(x, custom_w2v_model.wv, max_length=50)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xx2ffQxLGAYM",
        "outputId": "d86ee218-0c1b-4027-a071-fcbdb98bc555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 32.6 s (started: 2025-02-13 23:50:05 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create datasets for pretrained embeddings\n",
        "# bin classification\n",
        "binary_data_google = balanced_data[balanced_data['label'].isin([1, 2])].copy()\n",
        "binary_data_google['label'] = binary_data_google['label'].replace({1: 0, 2: 1})\n",
        "binary_data_google['sequence_embeddings'] = binary_data_google['sequence_embeddings_google']\n",
        "\n",
        "# ter classification\n",
        "ternary_data_google = balanced_data.copy()\n",
        "ternary_data_google['label'] = ternary_data_google['label'] - 1\n",
        "ternary_data_google['sequence_embeddings'] = ternary_data_google['sequence_embeddings_google']\n"
      ],
      "metadata": {
        "id": "bxdMhsP4srhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# train & eval\n",
        "# bin classf\n",
        "train_loader_bin_google, test_loader_bin_google = prepare_loaders(\n",
        "    binary_data_google, text_column='sequence_embeddings', label_column='label', test_size=ConfigValues.TEST_SPLIT, batch_size=16\n",
        ")\n",
        "model_bin_google = CNN(num_classes=2)\n",
        "criterion_bin_google = nn.CrossEntropyLoss()\n",
        "optimizer_bin_google = torch.optim.Adam(model_bin_google.parameters(), lr=0.001)\n",
        "train_model(model_bin_google, train_loader_bin_google, optimizer_bin_google, criterion_bin_google, epochs=10, device=device)\n",
        "accuracy_binary_pretrained = evaluate_model(model_bin_google, test_loader_bin_google, device=device)\n",
        "\n",
        "# tern classf\n",
        "train_loader_tern_google, test_loader_tern_google = prepare_loaders(\n",
        "    ternary_data_google, text_column='sequence_embeddings', label_column='label', test_size=ConfigValues.TEST_SPLIT, batch_size=16\n",
        ")\n",
        "model_tern_google = CNN(num_classes=3)\n",
        "criterion_tern_google = nn.CrossEntropyLoss()\n",
        "optimizer_tern_google = torch.optim.Adam(model_tern_google.parameters(), lr=0.001)\n",
        "train_model(model_tern_google, train_loader_tern_google, optimizer_tern_google, criterion_tern_google, epochs=10, device=device)\n",
        "accuracy_ternary_pretrained = evaluate_model(model_tern_google, test_loader_tern_google, device=device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N5glvTjiutWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5rmuWD3LIQN",
        "outputId": "ef81c9c3-de07-4e9e-efb7-d22ce2996a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 778 ms (started: 2025-02-13 23:52:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del google_pretrained_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWILpoKrLZYe",
        "outputId": "8dc2ea8e-cf8c-4a6a-c4e6-5db0025e3e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 311 µs (started: 2025-02-13 23:52:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create datasets for custom embeddings\n",
        "# bin classification\n",
        "binary_data_custom = balanced_data[balanced_data['label'].isin([1, 2])].copy()\n",
        "binary_data_custom['label'] = binary_data_custom['label'].replace({1: 0, 2: 1})\n",
        "binary_data_custom['sequence_embeddings'] = binary_data_custom['sequence_embeddings_custom']\n",
        "\n",
        "# ter classification\n",
        "ternary_data_custom = balanced_data.copy()\n",
        "ternary_data_custom['label'] = ternary_data_custom['label'] - 1\n",
        "binary_data_custom['sequence_embeddings'] = binary_data_custom['sequence_embeddings_custom']\n",
        "ternary_data_custom['sequence_embeddings'] = ternary_data_custom['sequence_embeddings_custom']"
      ],
      "metadata": {
        "id": "r8kcJnBTbxrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#t train & eval\n",
        "train_loader_bin_custom, test_loader_bin_custom = prepare_loaders(\n",
        "    binary_data_custom, text_column='sequence_embeddings', label_column='label', test_size=ConfigValues.TEST_SPLIT, batch_size=16\n",
        ")\n",
        "model_bin_custom = CNN(num_classes=2)\n",
        "criterion_bin_custom = nn.CrossEntropyLoss()\n",
        "optimizer_bin_custom = torch.optim.Adam(model_bin_custom.parameters(), lr=0.001)\n",
        "train_model(model_bin_custom, train_loader_bin_custom, optimizer_bin_custom, criterion_bin_custom, epochs=10, device=device)\n",
        "accuracy_binary_custom = evaluate_model(model_bin_custom, test_loader_bin_custom, device=device)\n",
        "\n",
        "# tern classf\n",
        "train_loader_tern_custom, test_loader_tern_custom = prepare_loaders(\n",
        "    ternary_data_custom, text_column='sequence_embeddings', label_column='label', test_size=ConfigValues.TEST_SPLIT, batch_size=16\n",
        ")\n",
        "model_tern_custom = CNN(num_classes=3)\n",
        "criterion_tern_custom = nn.CrossEntropyLoss()\n",
        "optimizer_tern_custom = torch.optim.Adam(model_tern_custom.parameters(), lr=0.001)\n",
        "train_model(model_tern_custom, train_loader_tern_custom, optimizer_tern_custom, criterion_tern_custom, epochs=10, device=device)\n",
        "accuracy_ternary_custom = evaluate_model(model_tern_custom, test_loader_tern_custom, device=device)"
      ],
      "metadata": {
        "id": "adwMa13UeSmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Binary Pretrained - Accuracy: {accuracy_binary_pretrained:.4f}\")\n",
        "print(f\"Binary Custom Model - Accuracy: {accuracy_binary_custom:.4f}\")\n",
        "print(f\"Ternary Pretrained - Accuracy: {accuracy_ternary_pretrained:.4f}\")\n",
        "print(f\"Ternary Custom Model - Accuracy: {accuracy_ternary_custom:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koZWJMJfGARg",
        "outputId": "fb9d0b59-6c29-43a6-ff61-56d2ea8d3a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Pretrained - Accuracy: 0.8575\n",
            "Binary Custom Model - Accuracy: 0.8978\n",
            "Ternary Pretrained - Accuracy: 0.7739\n",
            "Ternary Custom Model - Accuracy: 0.8132\n",
            "time: 545 µs (started: 2025-02-13 23:50:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2s78LSeF4Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baed on the above computations, consolidating the values:\n",
        "\n",
        "## Step 2 Word Embeddings:\n",
        "- Part a:\n",
        "Accuracy for Pre-trained model similarities :\n",
        "\n",
        "  ('queen', 0.7118193507194519)\n",
        "  \n",
        "  Similarity between 'excellent' and 'outstanding': 0.55674857\n",
        "\n",
        "\n",
        "- Part b:\n",
        "Accuracy Custom model similarities:\n",
        "\n",
        "  King : Man :: Woman : ('lady' , 0.6125918626785279)\n",
        "\n",
        "  Similarity between 'excellent' and 'outstanding': 0.37514123\n",
        "\n",
        "\n",
        "## Step 3 Simple models:\n",
        "\n",
        "**TF-IDF Features:**\n",
        "- Perceptron Accuracy: 0.669322\n",
        "- SVM Accuracy: 0.726016\n",
        "\n",
        "**Pre-trained Word2Vec Features:**\n",
        "- Perceptron Accuracy: 0.593336\n",
        "- SVM Accuracy: 0.664719\n",
        "\n",
        "**Custom Word2Vec Features:**\n",
        "- Perceptron Accuracy: 0.660576\n",
        "- SVM Accuracy: 0.692075\n",
        "\n",
        "\n",
        "## Step 4 Feedforward Neural Networks:\n",
        "\n",
        "**Part (a) - Average Word2Vec**\n",
        "Results:\n",
        "- Pretrained-Binary-Avg: 0.859334\n",
        "- Pretrained-Ternary-Avg: 0.696600\n",
        "- Custom-Binary-Avg: 0.878921\n",
        "- Custom-Ternary-Avg: 0.714872\n",
        "\n",
        "\n",
        "**Part (b) - Concatenated Word2Vec**\n",
        "Results:\n",
        "- Pretrained-Binary-Concat: 0.811603\n",
        "- Pretrained-Ternary-Concat: 0.652431\n",
        "- Custom-Binary-Concat: 0.819683\n",
        "- Custom-Ternary-Concat: 0.663398\n",
        "\n",
        "\n",
        "## Step 5 Convolutional Neural Networks:\n",
        "- Pretrained-Binary: 0.8575\n",
        "- Custom-Binary: 0.8978\n",
        "- Pretrained-Ternary: 0.7739\n",
        "- Custom-Ternary: 0.8132\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "fLmqAO8uvvB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "#### **Feature Representations**  \n",
        "- TF-IDF outperforms Word2Vec, achieving the highest accuracy in traditional models. Custom Word2Vec embeddings perform better than pretrained ones, especially in neural models.  \n",
        "\n",
        "#### **Model Comparisons**  \n",
        "- SVM consistently outperforms Perceptron, with TF-IDF giving the best results. MLP and CNN models surpass traditional models, with CNN achieving the highest accuracy.  \n",
        "\n",
        "#### **CNN Models**  \n",
        "- CNN's strong performance suggests deep learning models are more effective in sentiment analysis.  \n",
        "\n",
        "#### **Overall Performance**  \n",
        "CNN with Custom Word2Vec achieves the highest accuracy (89.78%). TF-IDF is best for traditional models, while Custom Word2Vec is ideal for deep learning approaches."
      ],
      "metadata": {
        "id": "JsCKmmW3uxhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE END"
      ],
      "metadata": {
        "id": "4IbUWtiQzCok"
      }
    }
  ]
}